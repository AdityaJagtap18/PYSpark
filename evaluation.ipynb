{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIG\n",
    "# -----------------------------\n",
    "K = 12\n",
    "MODEL_PATH = \"data/hnm/models/logreg.joblib\"   # change if needed\n",
    "DATA_PATH  = \"data/hnm/processed/transactions_sample.csv\"\n",
    "ITEMS_PATH = \"data/hnm/processed/articles_features.csv\"\n",
    "USERS_PATH = \"data/hnm/processed/customers_features.csv\"\n",
    "\n",
    "OUT_DIR = \"data/hnm/tableau\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD\n",
    "# -----------------------------\n",
    "model = joblib.load(MODEL_PATH)\n",
    "\n",
    "tx = pd.read_csv(DATA_PATH, dtype={\"customer_id\": str, \"article_id\": str})\n",
    "items = pd.read_csv(ITEMS_PATH, dtype={\"article_id\": str})\n",
    "users = pd.read_csv(USERS_PATH, dtype={\"customer_id\": str})\n",
    "\n",
    "# positives only\n",
    "tx = tx.drop_duplicates(subset=[\"customer_id\", \"article_id\"])\n",
    "tx[\"label\"] = 1\n",
    "\n",
    "# -----------------------------\n",
    "# BUILD CANDIDATE SET\n",
    "# (customer Ã— sampled items)\n",
    "# -----------------------------\n",
    "rng = np.random.default_rng(42)\n",
    "all_articles = items[\"article_id\"].unique()\n",
    "\n",
    "rows = []\n",
    "for cust, grp in tx.groupby(\"customer_id\"):\n",
    "    bought = set(grp[\"article_id\"])\n",
    "    candidates = set(bought)\n",
    "\n",
    "    while len(candidates) < 200:   # candidate pool size\n",
    "        candidates.add(rng.choice(all_articles))\n",
    "\n",
    "    for a in candidates:\n",
    "        rows.append((cust, a, int(a in bought)))\n",
    "\n",
    "eval_df = pd.DataFrame(rows, columns=[\"customer_id\", \"article_id\", \"label\"])\n",
    "\n",
    "# join features\n",
    "eval_df = eval_df.merge(items, on=\"article_id\", how=\"left\")\n",
    "eval_df = eval_df.merge(users, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "X = eval_df.drop(columns=[\"label\"])\n",
    "y = eval_df[\"label\"]\n",
    "\n",
    "# -----------------------------\n",
    "# PREDICT\n",
    "# -----------------------------\n",
    "eval_df[\"score\"] = model.predict_proba(X)[:, 1]\n",
    "\n",
    "# -----------------------------\n",
    "# TOP-K PER CUSTOMER\n",
    "# -----------------------------\n",
    "topk = (\n",
    "    eval_df.sort_values([\"customer_id\", \"score\"], ascending=[True, False])\n",
    "           .groupby(\"customer_id\")\n",
    "           .head(K)\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# METRIC FUNCTIONS\n",
    "# -----------------------------\n",
    "def apk(actual, predicted, k):\n",
    "    score = 0.0\n",
    "    hits = 0.0\n",
    "    for i, p in enumerate(predicted[:k]):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            hits += 1\n",
    "            score += hits / (i + 1)\n",
    "    return score / min(len(actual), k) if actual else 0.0\n",
    "\n",
    "def ndcg(actual, predicted, k):\n",
    "    dcg = sum(\n",
    "        1 / np.log2(i + 2)\n",
    "        for i, p in enumerate(predicted[:k])\n",
    "        if p in actual\n",
    "    )\n",
    "    idcg = sum(1 / np.log2(i + 2) for i in range(min(len(actual), k)))\n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "# -----------------------------\n",
    "# CUSTOMER-LEVEL METRICS\n",
    "# -----------------------------\n",
    "records = []\n",
    "\n",
    "for cust, grp in topk.groupby(\"customer_id\"):\n",
    "    actual = set(eval_df[(eval_df.customer_id == cust) & (eval_df.label == 1)][\"article_id\"])\n",
    "    predicted = grp[\"article_id\"].tolist()\n",
    "\n",
    "    hits = len(actual.intersection(predicted))\n",
    "    precision = hits / K\n",
    "    recall = hits / len(actual) if actual else 0\n",
    "    mapk = apk(actual, predicted, K)\n",
    "    ndcgk = ndcg(actual, predicted, K)\n",
    "\n",
    "    records.append([\n",
    "        cust, hits, precision, recall, mapk, ndcgk\n",
    "    ])\n",
    "\n",
    "cust_metrics = pd.DataFrame(\n",
    "    records,\n",
    "    columns=[\n",
    "        \"customer_id\",\n",
    "        \"hits_at_12\",\n",
    "        \"precision_at_12\",\n",
    "        \"recall_at_12\",\n",
    "        \"map_at_12\",\n",
    "        \"ndcg_at_12\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# OVERALL METRICS\n",
    "# -----------------------------\n",
    "overall = pd.DataFrame([{\n",
    "    \"customers_evaluated\": len(cust_metrics),\n",
    "    \"mean_precision_at_12\": cust_metrics[\"precision_at_12\"].mean(),\n",
    "    \"mean_recall_at_12\": cust_metrics[\"recall_at_12\"].mean(),\n",
    "    \"MAP@12\": cust_metrics[\"map_at_12\"].mean(),\n",
    "    \"NDCG@12\": cust_metrics[\"ndcg_at_12\"].mean(),\n",
    "}])\n",
    "\n",
    "# -----------------------------\n",
    "# SAVE FOR TABLEAU\n",
    "# -----------------------------\n",
    "cust_metrics.to_csv(f\"{OUT_DIR}/customer_level_metrics.csv\", index=False)\n",
    "overall.to_csv(f\"{OUT_DIR}/overall_metrics.csv\", index=False)\n",
    "\n",
    "topk_out = topk[[\"customer_id\", \"article_id\", \"score\"]]\n",
    "topk_out[\"rank\"] = topk_out.groupby(\"customer_id\")[\"score\"].rank(ascending=False, method=\"first\")\n",
    "topk_out.to_csv(f\"{OUT_DIR}/topk_recommendations.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Evaluation complete\")\n",
    "print(\"ðŸ“Š CSVs written to:\", OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
