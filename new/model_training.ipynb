{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "885535c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read chunk 1\n",
      "Read chunk 2\n",
      "Read chunk 3\n",
      "Read chunk 4\n",
      "Read chunk 5\n",
      "Read chunk 6\n",
      "Read chunk 7\n",
      "Read chunk 8\n",
      "Read chunk 9\n",
      "Read chunk 10\n",
      "Read chunk 11\n",
      "Read chunk 12\n",
      "Read chunk 13\n",
      "Read chunk 14\n",
      "Read chunk 15\n",
      "Read chunk 16\n",
      "Read chunk 17\n",
      "Read chunk 18\n",
      "Read chunk 19\n",
      "Read chunk 20\n",
      "Read chunk 21\n",
      "Read chunk 22\n",
      "Read chunk 23\n",
      "Read chunk 24\n",
      "Read chunk 25\n",
      "Read chunk 26\n",
      "Read chunk 27\n",
      "Read chunk 28\n",
      "Read chunk 29\n",
      "Read chunk 30\n",
      "Read chunk 31\n",
      "Read chunk 32\n",
      "Saved: data/hnm/processed/transactions_sample.csv shape: (1788324, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "src = \"data/hnm/transactions_train.csv\"\n",
    "out = \"data/hnm/processed/transactions_sample.csv\"\n",
    "os.makedirs(\"data/hnm/processed\", exist_ok=True)\n",
    "\n",
    "# Take last ~2M rows by reading in chunks and keeping recent chunks\n",
    "chunksize = 1_000_000\n",
    "keep_chunks = []\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv(src, chunksize=chunksize, dtype={\"customer_id\": str, \"article_id\": str})):\n",
    "    keep_chunks.append(chunk)\n",
    "    # keep only last 2 chunks (~2M rows) in memory\n",
    "    if len(keep_chunks) > 2:\n",
    "        keep_chunks.pop(0)\n",
    "    print(f\"Read chunk {i+1}\")\n",
    "\n",
    "sample = pd.concat(keep_chunks, ignore_index=True)\n",
    "sample.to_csv(out, index=False)\n",
    "print(\"Saved:\", out, \"shape:\", sample.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fed5d73",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 70\u001b[39m\n\u001b[32m     65\u001b[39m data = pd.concat([tx[[\u001b[33m\"\u001b[39m\u001b[33mcustomer_id\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33marticle_id\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m]], neg], ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# Join engineered features (users + items)\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# -----------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m data = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marticle_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mleft\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m data = data.merge(users, on=\u001b[33m\"\u001b[39m\u001b[33mcustomer_id\u001b[39m\u001b[33m\"\u001b[39m, how=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# Drop rows where merges failed (rare if ids mismatch)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/frame.py:12884\u001b[39m, in \u001b[36mDataFrame.merge\u001b[39m\u001b[34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m  12880\u001b[39m \u001b[38;5;28mself\u001b[39m._check_copy_deprecation(copy)\n\u001b[32m  12882\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mreshape\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[32m> \u001b[39m\u001b[32m12884\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m  12885\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m  12886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12889\u001b[39m \u001b[43m    \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12893\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12894\u001b[39m \u001b[43m    \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m  12897\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py:399\u001b[39m, in \u001b[36mmerge\u001b[39m\u001b[34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    385\u001b[39m     op = _MergeOperation(\n\u001b[32m    386\u001b[39m         left_df,\n\u001b[32m    387\u001b[39m         right_df,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m         validate=validate,\n\u001b[32m    398\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py:1141\u001b[39m, in \u001b[36m_MergeOperation.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.indicator:\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right = \u001b[38;5;28mself\u001b[39m._indicator_pre_merge(\u001b[38;5;28mself\u001b[39m.left, \u001b[38;5;28mself\u001b[39m.right)\n\u001b[32m-> \u001b[39m\u001b[32m1141\u001b[39m join_index, left_indexer, right_indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_join_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1143\u001b[39m result = \u001b[38;5;28mself\u001b[39m._reindex_and_concat(join_index, left_indexer, right_indexer)\n\u001b[32m   1145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.indicator:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py:1423\u001b[39m, in \u001b[36m_MergeOperation._get_join_info\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m     join_index, right_indexer, left_indexer = _left_join_on_index(\n\u001b[32m   1420\u001b[39m         right_ax, left_ax, \u001b[38;5;28mself\u001b[39m.right_join_keys, sort=\u001b[38;5;28mself\u001b[39m.sort\n\u001b[32m   1421\u001b[39m     )\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1423\u001b[39m     (left_indexer, right_indexer) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_join_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1425\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.right_index:\n\u001b[32m   1426\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.left) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py:1397\u001b[39m, in \u001b[36m_MergeOperation._get_join_indexers\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1395\u001b[39m \u001b[38;5;66;03m# make mypy happy\u001b[39;00m\n\u001b[32m   1396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.how != \u001b[33m\"\u001b[39m\u001b[33masof\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1397\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_join_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mleft_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mright_join_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhow\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/reshape/merge.py:2104\u001b[39m, in \u001b[36mget_join_indexers\u001b[39m\u001b[34m(left_keys, right_keys, sort, how)\u001b[39m\n\u001b[32m   2100\u001b[39m left = Index(lkey, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   2101\u001b[39m right = Index(rkey, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   2103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m2104\u001b[39m     \u001b[43mleft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_monotonic_increasing\u001b[49m\n\u001b[32m   2105\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m right.is_monotonic_increasing\n\u001b[32m   2106\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (left.is_unique \u001b[38;5;129;01mor\u001b[39;00m right.is_unique)\n\u001b[32m   2107\u001b[39m ):\n\u001b[32m   2108\u001b[39m     _, lidx, ridx = left.join(right, how=how, return_indexers=\u001b[38;5;28;01mTrue\u001b[39;00m, sort=sort)\n\u001b[32m   2109\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:2395\u001b[39m, in \u001b[36mIndex.is_monotonic_increasing\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2373\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   2374\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_monotonic_increasing\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m   2375\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2376\u001b[39m \u001b[33;03m    Return a boolean if the values are equal or increasing.\u001b[39;00m\n\u001b[32m   2377\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2393\u001b[39m \u001b[33;03m    False\u001b[39;00m\n\u001b[32m   2394\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2395\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m.is_monotonic_increasing\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/properties.pyx:36\u001b[39m, in \u001b[36mpandas._libs.properties.CachedProperty.__get__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:854\u001b[39m, in \u001b[36mIndex._engine\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    849\u001b[39m \u001b[38;5;129m@cache_readonly\u001b[39m\n\u001b[32m    850\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_engine\u001b[39m(\n\u001b[32m    851\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    852\u001b[39m ) -> libindex.IndexEngine | libindex.ExtensionEngine | libindex.MaskedIndexEngine:\n\u001b[32m    853\u001b[39m     \u001b[38;5;66;03m# For base class (object dtype) we get ObjectEngine\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m854\u001b[39m     target_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_engine_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._values, ArrowExtensionArray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMm\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    857\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyarrow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpa\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:5158\u001b[39m, in \u001b[36mIndex._get_engine_target\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   5145\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m vals._ndarray.view(\u001b[33m\"\u001b[39m\u001b[33mi8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5146\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   5147\u001b[39m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Index\n\u001b[32m   5148\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._values, ExtensionArray)\n\u001b[32m   (...)\u001b[39m\u001b[32m   5156\u001b[39m ):\n\u001b[32m   5157\u001b[39m     \u001b[38;5;66;03m# TODO(ExtensionIndex): remove special-case, just use self._values\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_values\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   5159\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vals\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/arrays/string_arrow.py:330\u001b[39m, in \u001b[36mArrowStringArray.astype\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m np.issubdtype(dtype, np.floating):\n\u001b[32m    328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_numpy(dtype=dtype, na_value=np.nan)\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/arrays/base.py:831\u001b[39m, in \u001b[36mExtensionArray.astype\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m    829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray(\u001b[38;5;28mself\u001b[39m, dtype=dtype)\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m831\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/arrays/arrow/array.py:862\u001b[39m, in \u001b[36mArrowExtensionArray.__array__\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    859\u001b[39m     \u001b[38;5;66;03m# `to_numpy(copy=False)` has the meaning of NumPy `copy=None`.\u001b[39;00m\n\u001b[32m    860\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/bobadehelp/venv/lib/python3.12/site-packages/pandas/core/arrays/arrow/array.py:1711\u001b[39m, in \u001b[36mArrowExtensionArray.to_numpy\u001b[39m\u001b[34m(self, dtype, copy, na_value)\u001b[39m\n\u001b[32m   1699\u001b[39m     result = np.full(\u001b[38;5;28mlen\u001b[39m(data), fill_value=na_value, dtype=dtype)\n\u001b[32m   1700\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data._hasna \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1701\u001b[39m     pa.types.is_floating(pa_type)\n\u001b[32m   1702\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m   1709\u001b[39m     )\n\u001b[32m   1710\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1711\u001b[39m     result = \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_pa_array\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1712\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1713\u001b[39m         result = result.astype(dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import joblib\n",
    "\n",
    "# -----------------------\n",
    "# Paths (your processed outputs)\n",
    "# -----------------------\n",
    "items_path = \"data/hnm/processed/articles_features.csv\"\n",
    "users_path = \"data/hnm/processed/customers_features.csv\"\n",
    "tx_path    = \"data/hnm/processed/transactions_sample.csv\"  # use sample first\n",
    "\n",
    "os.makedirs(\"data/hnm/models\", exist_ok=True)\n",
    "\n",
    "# -----------------------\n",
    "# Load\n",
    "# -----------------------\n",
    "items = pd.read_csv(items_path, dtype={\"article_id\": str})\n",
    "users = pd.read_csv(users_path, dtype={\"customer_id\": str})\n",
    "tx    = pd.read_csv(tx_path, dtype={\"customer_id\": str, \"article_id\": str})\n",
    "\n",
    "# Minimal clean\n",
    "tx = tx.drop_duplicates(subset=[\"customer_id\", \"article_id\"])\n",
    "tx[\"label\"] = 1\n",
    "\n",
    "# -----------------------\n",
    "# Negative sampling\n",
    "# For each customer: sample N not-bought articles\n",
    "# -----------------------\n",
    "rng = np.random.default_rng(42)\n",
    "all_articles = items[\"article_id\"].unique()\n",
    "\n",
    "cust_buys = tx.groupby(\"customer_id\")[\"article_id\"].apply(set).to_dict()\n",
    "\n",
    "NEG_PER_POS = 2  # increase to 5 later if you want stronger training set\n",
    "\n",
    "neg_rows = []\n",
    "for cust, bought in cust_buys.items():\n",
    "    n_pos = len(bought)\n",
    "    n_neg = n_pos * NEG_PER_POS\n",
    "\n",
    "    sampled = set()\n",
    "    # fast sampling loop\n",
    "    while len(sampled) < n_neg:\n",
    "        pick = rng.choice(all_articles, size=min(2000, len(all_articles)), replace=False)\n",
    "        for a in pick:\n",
    "            if a not in bought:\n",
    "                sampled.add(a)\n",
    "            if len(sampled) >= n_neg:\n",
    "                break\n",
    "\n",
    "    for a in sampled:\n",
    "        neg_rows.append((cust, a, 0))\n",
    "\n",
    "neg = pd.DataFrame(neg_rows, columns=[\"customer_id\", \"article_id\", \"label\"])\n",
    "\n",
    "data = pd.concat([tx[[\"customer_id\",\"article_id\",\"label\"]], neg], ignore_index=True)\n",
    "\n",
    "# -----------------------\n",
    "# Join engineered features (users + items)\n",
    "# -----------------------\n",
    "data = data.merge(items, on=\"article_id\", how=\"left\")\n",
    "data = data.merge(users, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "# Drop rows where merges failed (rare if ids mismatch)\n",
    "data = data.dropna(subset=[\"customer_id\", \"article_id\"])\n",
    "\n",
    "# -----------------------\n",
    "# Train/Test split\n",
    "# -----------------------\n",
    "train_df, test_df = train_test_split(\n",
    "    data, test_size=0.2, random_state=42, stratify=data[\"label\"]\n",
    ")\n",
    "\n",
    "X_train = train_df.drop(columns=[\"label\"])\n",
    "y_train = train_df[\"label\"].astype(int)\n",
    "X_test  = test_df.drop(columns=[\"label\"])\n",
    "y_test  = test_df[\"label\"].astype(int)\n",
    "\n",
    "# -----------------------\n",
    "# Preprocess for ML models\n",
    "# -----------------------\n",
    "cat_cols = [c for c in X_train.columns if X_train[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Model 1: Popularity baseline (ranking proxy)\n",
    "# -----------------------\n",
    "# popularity from positives\n",
    "pop = tx[\"article_id\"].value_counts()\n",
    "pop_rank = {aid: (len(pop) - i) for i, aid in enumerate(pop.index)}  # higher=more popular\n",
    "\n",
    "baseline_scores = X_test[\"article_id\"].map(lambda a: pop_rank.get(a, 0)).astype(float)\n",
    "\n",
    "print(\"\\nModel 1) Popularity baseline\")\n",
    "print(\"AUC   :\", roc_auc_score(y_test, baseline_scores))\n",
    "print(\"PR-AUC:\", average_precision_score(y_test, baseline_scores))\n",
    "\n",
    "# -----------------------\n",
    "# Helper: train & evaluate\n",
    "# -----------------------\n",
    "def train_eval_save(name, clf, filename):\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    proba = pipe.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, proba)\n",
    "    pr = average_precision_score(y_test, proba)\n",
    "\n",
    "    print(f\"\\n{name}\")\n",
    "    print(\"AUC   :\", auc)\n",
    "    print(\"PR-AUC:\", pr)\n",
    "\n",
    "    joblib.dump(pipe, f\"data/hnm/models/{filename}\")\n",
    "    print(\"Saved model ->\", f\"data/hnm/models/{filename}\")\n",
    "    return pipe\n",
    "\n",
    "# -----------------------\n",
    "# Model 2: Logistic Regression\n",
    "# -----------------------\n",
    "m2 = train_eval_save(\n",
    "    \"Model 2) Logistic Regression\",\n",
    "    LogisticRegression(max_iter=300),\n",
    "    \"logreg.joblib\"\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Model 3: Random Forest\n",
    "# -----------------------\n",
    "m3 = train_eval_save(\n",
    "    \"Model 3) Random Forest\",\n",
    "    RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=42),\n",
    "    \"rf.joblib\"\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Model 4: Gradient Boosting (strong baseline without extra installs)\n",
    "# -----------------------\n",
    "m4 = train_eval_save(\n",
    "    \"Model 4) Gradient Boosting\",\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    \"gbdt.joblib\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
