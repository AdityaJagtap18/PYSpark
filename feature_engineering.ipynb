{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba99692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6738/434231438.py:29: Pandas4Warning: For backward compatibility, 'str' dtypes are included by select_dtypes when 'object' dtype is specified. This behavior is deprecated and will be removed in a future version. Explicitly pass 'str' to `include` to select them, or to `exclude` to remove them and silence this warning.\n",
      "See https://pandas.pydata.org/docs/user_guide/migration-3-strings.html#string-migration-select-dtypes for details on how to write code that works with pandas 2 and 3.\n",
      "  obj_cols = df.select_dtypes(include=[\"object\"]).columns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - Cleaned: data/hnm/processed/articles_cleaned.csv\n",
      " - Features: data/hnm/processed/articles_features.csv\n",
      "Feature shape: (105542, 109)\n",
      "Columns sample: ['article_id', 'product_code', 'product_type_name_freq', 'product_group_name_freq', 'graphical_appearance_name_freq', 'colour_group_name_freq', 'perceived_colour_value_name_freq', 'department_name_freq', 'index_name_freq', 'index_group_name_freq', 'section_name_freq', 'garment_group_name_freq', 'text_len', 'text_word_count', 'has_description', 'colour_group_name_norm', 'product_group_name_Accessories', 'product_group_name_Bags', 'product_group_name_Cosmetic', 'product_group_name_Fun']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- paths ----\n",
    "in_path  = \"data/hnm/articles.csv\"\n",
    "out_dir  = \"data/hnm/processed\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# ---- load ----\n",
    "df = pd.read_csv(in_path)\n",
    "\n",
    "# =========================\n",
    "# 1) BASIC CLEANING\n",
    "# =========================\n",
    "\n",
    "# standardize column names (optional)\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# drop exact duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# ensure article_id is string (keeps leading zeros if any)\n",
    "if \"article_id\" in df.columns:\n",
    "    df[\"article_id\"] = df[\"article_id\"].astype(str)\n",
    "\n",
    "# trim whitespace in object columns\n",
    "obj_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "for c in obj_cols:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# handle known \"nan\" strings (sometimes appear after astype(str))\n",
    "df = df.replace({\"nan\": np.nan, \"None\": np.nan, \"\": np.nan})\n",
    "\n",
    "# fill missing for key categorical columns with \"Unknown\"\n",
    "cat_like = [\n",
    "    \"product_type_name\",\"product_group_name\",\"graphical_appearance_name\",\n",
    "    \"colour_group_name\",\"perceived_colour_value_name\",\"department_name\",\n",
    "    \"index_name\",\"index_group_name\",\"section_name\",\"garment_group_name\"\n",
    "]\n",
    "for c in cat_like:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "# detail_desc: fill missing with empty string for NLP-friendly features\n",
    "if \"detail_desc\" in df.columns:\n",
    "    df[\"detail_desc\"] = df[\"detail_desc\"].fillna(\"\")\n",
    "\n",
    "# =========================\n",
    "# 2) FEATURE ENGINEERING\n",
    "# =========================\n",
    "\n",
    "# ---- (A) price features ----\n",
    "# articles.csv usually has price in SEK? (or float). We'll add bins & log.\n",
    "if \"price\" in df.columns:\n",
    "    df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
    "    df[\"price_missing\"] = df[\"price\"].isna().astype(int)\n",
    "    df[\"price_filled\"] = df[\"price\"].fillna(df[\"price\"].median())\n",
    "    df[\"price_log1p\"] = np.log1p(df[\"price_filled\"])\n",
    "\n",
    "    # quantile bins (robust)\n",
    "    try:\n",
    "        df[\"price_bin_q\"] = pd.qcut(df[\"price_filled\"], q=10, duplicates=\"drop\")\n",
    "        df[\"price_bin_q\"] = df[\"price_bin_q\"].astype(str)\n",
    "    except ValueError:\n",
    "        df[\"price_bin_q\"] = \"bin_unavailable\"\n",
    "\n",
    "# ---- (B) text features from product name + detail_desc ----\n",
    "def clean_text(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[^a-z0-9\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "text_cols = []\n",
    "if \"prod_name\" in df.columns: text_cols.append(\"prod_name\")\n",
    "if \"detail_desc\" in df.columns: text_cols.append(\"detail_desc\")\n",
    "\n",
    "if text_cols:\n",
    "    df[\"text_all\"] = (\n",
    "        df[text_cols]\n",
    "        .fillna(\"\")\n",
    "        .astype(str)\n",
    "        .agg(\" \".join, axis=1)\n",
    "        .map(clean_text)\n",
    "    )\n",
    "    df[\"text_len\"] = df[\"text_all\"].str.len()\n",
    "    df[\"text_word_count\"] = df[\"text_all\"].str.split().map(len)\n",
    "    df[\"has_description\"] = (df[\"detail_desc\"].fillna(\"\").str.len() > 0).astype(int) if \"detail_desc\" in df.columns else 0\n",
    "\n",
    "# ---- (C) color normalization helpers ----\n",
    "if \"colour_group_name\" in df.columns:\n",
    "    df[\"colour_group_name_norm\"] = df[\"colour_group_name\"].str.lower()\n",
    "\n",
    "# ---- (D) lightweight categorical encodings ----\n",
    "# 1) frequency encoding (often better than one-hot for high-cardinality)\n",
    "def freq_encode(series: pd.Series) -> pd.Series:\n",
    "    freq = series.value_counts(dropna=False)\n",
    "    return series.map(freq).astype(float)\n",
    "\n",
    "for c in cat_like:\n",
    "    if c in df.columns:\n",
    "        df[f\"{c}_freq\"] = freq_encode(df[c])\n",
    "\n",
    "# 2) optional: one-hot only for low-cardinality columns (safe)\n",
    "low_card_cols = []\n",
    "for c in cat_like:\n",
    "    if c in df.columns and df[c].nunique() <= 30:\n",
    "        low_card_cols.append(c)\n",
    "\n",
    "df_onehot = pd.get_dummies(df[low_card_cols], prefix=low_card_cols) if low_card_cols else pd.DataFrame(index=df.index)\n",
    "\n",
    "# ---- (E) build final feature table ----\n",
    "keep_id_cols = [c for c in [\"article_id\", \"product_code\"] if c in df.columns]\n",
    "\n",
    "numeric_feats = [c for c in df.columns if c.endswith((\"_freq\", \"_log1p\"))] + \\\n",
    "                [c for c in [\"text_len\",\"text_word_count\",\"has_description\",\"price_filled\",\"price_missing\"] if c in df.columns]\n",
    "\n",
    "cat_feats = [c for c in [\"price_bin_q\",\"colour_group_name_norm\"] if c in df.columns]\n",
    "\n",
    "features = pd.concat(\n",
    "    [\n",
    "        df[keep_id_cols + numeric_feats + cat_feats].copy(),\n",
    "        df_onehot\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3) SAVE OUTPUTS\n",
    "# =========================\n",
    "features_path = os.path.join(out_dir, \"articles_features.csv\")\n",
    "cleaned_path  = os.path.join(out_dir, \"articles_cleaned.csv\")\n",
    "\n",
    "features.to_csv(features_path, index=False)\n",
    "df.to_csv(cleaned_path, index=False)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" - Cleaned:\", cleaned_path)\n",
    "print(\" - Features:\", features_path)\n",
    "print(\"Feature shape:\", features.shape)\n",
    "print(\"Columns sample:\", features.columns[:20].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f062382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/hnm/processed/customers_features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "in_path = \"data/hnm/customers.csv\"\n",
    "out_path = \"data/hnm/processed/customers_features.csv\"\n",
    "os.makedirs(\"data/hnm/processed\", exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(in_path, dtype={\"customer_id\": str})\n",
    "\n",
    "# ---- cleaning ----\n",
    "df = df.drop_duplicates()\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# age\n",
    "if \"age\" in df.columns:\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"], errors=\"coerce\")\n",
    "    df[\"age_missing\"] = df[\"age\"].isna().astype(int)\n",
    "    df[\"age\"] = df[\"age\"].fillna(df[\"age\"].median())\n",
    "    df[\"age_bin\"] = pd.cut(df[\"age\"], bins=[0,18,25,35,45,55,65,100], labels=False)\n",
    "\n",
    "# categorical columns\n",
    "cat_cols = [\"fashion_news_frequency\", \"club_member_status\", \"postal_code\"]\n",
    "for c in cat_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna(\"Unknown\")\n",
    "\n",
    "# frequency encoding\n",
    "for c in cat_cols:\n",
    "    if c in df.columns:\n",
    "        df[f\"{c}_freq\"] = df[c].map(df[c].value_counts())\n",
    "\n",
    "# keep final features\n",
    "keep = [\"customer_id\", \"age\", \"age_missing\", \"age_bin\"] + \\\n",
    "       [c for c in df.columns if c.endswith(\"_freq\")]\n",
    "\n",
    "features = df[keep]\n",
    "features.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "326c5a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: data/hnm/processed/transactions_features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "in_path = \"data/hnm/transactions_train.csv\"\n",
    "out_path = \"data/hnm/processed/transactions_features.csv\"\n",
    "os.makedirs(\"data/hnm/processed\", exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(in_path, dtype={\"customer_id\": str, \"article_id\": str})\n",
    "\n",
    "# ---- cleaning ----\n",
    "df = df.drop_duplicates()\n",
    "df[\"t_dat\"] = pd.to_datetime(df[\"t_dat\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"t_dat\"])\n",
    "\n",
    "# ---- time features ----\n",
    "df[\"year\"] = df[\"t_dat\"].dt.year\n",
    "df[\"month\"] = df[\"t_dat\"].dt.month\n",
    "df[\"day\"] = df[\"t_dat\"].dt.day\n",
    "df[\"dayofweek\"] = df[\"t_dat\"].dt.dayofweek\n",
    "df[\"weekofyear\"] = df[\"t_dat\"].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# ---- recency feature ----\n",
    "max_date = df[\"t_dat\"].max()\n",
    "df[\"days_since_purchase\"] = (max_date - df[\"t_dat\"]).dt.days\n",
    "\n",
    "# ---- interaction strength ----\n",
    "# each row = 1 interaction\n",
    "df[\"interaction\"] = 1\n",
    "\n",
    "df = df[\n",
    "    [\n",
    "        \"customer_id\",\n",
    "        \"article_id\",\n",
    "        \"interaction\",\n",
    "        \"days_since_purchase\",\n",
    "        \"dayofweek\",\n",
    "        \"weekofyear\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Saved:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
